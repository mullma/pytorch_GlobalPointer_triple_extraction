2022-06-29 11:48:12,004 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-29 11:49:58,527 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-29 11:50:31,279 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-29 11:50:47,094 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-29 11:51:29,678 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-29 11:51:36,701 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:11:39,922 - INFO - main.py - <module> - 294 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 02:12:03,590 - INFO - main.py - <module> - 294 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 02:12:30,170 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:12:41,438 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 02:12:42,516 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:26:07,338 - INFO - main.py - <module> - 245 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 02:26:14,214 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:26:22,612 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 02:26:23,623 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:27:46,714 - INFO - main.py - <module> - 245 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 02:27:53,669 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:28:02,258 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 02:28:03,191 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:28:52,891 - INFO - main.py - <module> - 245 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 02:28:59,734 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:29:08,295 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 02:29:09,217 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:32:00,288 - INFO - main.py - <module> - 247 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 02:32:07,429 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:32:16,005 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 02:32:17,131 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:32:59,456 - INFO - main.py - <module> - 247 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 02:33:06,349 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:33:14,933 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 02:33:15,858 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:35:54,312 - INFO - main.py - <module> - 246 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 02:36:01,613 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:36:10,140 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 02:36:11,075 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:36:43,697 - INFO - main.py - <module> - 247 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 02:36:50,572 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:36:59,058 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 02:36:59,988 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:38:37,012 - INFO - main.py - <module> - 248 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 02:38:43,990 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:38:52,993 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 02:38:54,328 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:44:44,645 - INFO - main.py - <module> - 258 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 02:44:51,599 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:45:00,068 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 02:45:01,028 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:45:54,371 - INFO - main.py - <module> - 258 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 02:46:01,411 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:46:09,887 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 02:46:10,848 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:47:06,798 - INFO - main.py - <module> - 259 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 02:47:14,152 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:47:23,172 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 02:47:24,137 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:50:17,231 - INFO - main.py - <module> - 261 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 02:50:24,204 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:50:32,708 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 02:50:33,671 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:52:15,179 - INFO - main.py - <module> - 266 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 02:52:22,175 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:52:30,733 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 02:52:31,705 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:55:04,553 - INFO - main.py - <module> - 267 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 02:55:12,311 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:55:21,395 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 02:55:22,548 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:57:29,336 - INFO - main.py - <module> - 281 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 02:57:36,520 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:57:45,085 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 02:57:46,024 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:58:51,474 - INFO - main.py - <module> - 281 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 02:58:58,431 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 02:59:06,975 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 02:59:07,942 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:09:03,482 - INFO - main.py - <module> - 276 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 03:09:10,471 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:09:19,054 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 03:09:20,034 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:10:58,013 - INFO - main.py - <module> - 276 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 03:11:04,963 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:11:13,499 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 03:11:14,463 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:14:59,353 - INFO - main.py - <module> - 279 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 03:15:06,319 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:15:14,828 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 03:15:15,757 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:17:16,243 - INFO - main.py - <module> - 279 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 03:17:23,241 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:17:31,867 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 03:17:32,805 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:17:44,900 - INFO - main.py - <module> - 279 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 03:17:51,854 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:18:00,426 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 03:18:01,536 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:19:47,623 - INFO - main.py - <module> - 279 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 03:19:54,624 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:20:03,068 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 03:20:04,020 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:24:38,076 - INFO - main.py - <module> - 312 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 03:24:45,025 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:24:53,688 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 03:24:54,664 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:26:50,811 - INFO - main.py - <module> - 313 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 03:26:57,934 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:27:06,607 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 03:27:07,579 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:30:37,398 - INFO - main.py - <module> - 314 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 03:30:44,394 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:30:52,927 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 03:30:53,908 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:31:15,955 - INFO - main.py - <module> - 314 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 03:31:22,841 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:31:31,424 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 03:31:32,384 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:33:07,563 - INFO - main.py - <module> - 316 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 03:33:14,542 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:33:23,172 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 03:33:24,134 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:35:02,581 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 03:35:09,602 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:35:18,845 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 03:35:19,804 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:36:22,396 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=100, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 03:36:33,832 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=10, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 03:36:40,826 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:36:48,812 - INFO - main.py - train - 64 - 【train】 epoch:0 0/5406 loss:269.4182 entity_loss:16.4784 head_loss:395.4211 tail_loss:396.3550
2022-06-30 03:36:50,498 - INFO - main.py - train - 64 - 【train】 epoch:0 1/5406 loss:270.2010 entity_loss:16.5278 head_loss:396.7143 tail_loss:397.3611
2022-06-30 03:36:52,189 - INFO - main.py - train - 64 - 【train】 epoch:0 2/5406 loss:266.3738 entity_loss:16.2139 head_loss:391.1121 tail_loss:391.7955
2022-06-30 03:36:53,879 - INFO - main.py - train - 64 - 【train】 epoch:0 3/5406 loss:269.4011 entity_loss:16.5687 head_loss:395.5172 tail_loss:396.1174
2022-06-30 03:36:55,569 - INFO - main.py - train - 64 - 【train】 epoch:0 4/5406 loss:250.0257 entity_loss:15.3507 head_loss:367.0298 tail_loss:367.6967
2022-06-30 03:36:57,281 - INFO - main.py - train - 64 - 【train】 epoch:0 5/5406 loss:259.6663 entity_loss:15.8807 head_loss:381.1756 tail_loss:381.9426
2022-06-30 03:36:58,986 - INFO - main.py - train - 64 - 【train】 epoch:0 6/5406 loss:256.6382 entity_loss:15.6712 head_loss:376.7637 tail_loss:377.4796
2022-06-30 03:37:00,694 - INFO - main.py - train - 64 - 【train】 epoch:0 7/5406 loss:271.7689 entity_loss:16.6315 head_loss:398.9182 tail_loss:399.7569
2022-06-30 03:37:02,421 - INFO - main.py - train - 64 - 【train】 epoch:0 8/5406 loss:258.0942 entity_loss:15.7037 head_loss:378.8968 tail_loss:379.6821
2022-06-30 03:37:04,130 - INFO - main.py - train - 64 - 【train】 epoch:0 9/5406 loss:258.2488 entity_loss:15.8331 head_loss:379.0878 tail_loss:379.8255
2022-06-30 03:48:08,606 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='model_hub/chinese-bert-wwm-ext/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=8, eval_steps=10, gpu_ids='0', log_dir='./logs/', lr=5e-05, max_grad_norm=1.0, max_seq_len=256, num_tags=49, other_lr=5e-05, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=1, use_dev_num=1000, use_tensorboard='False', warmup_proportion=0.1, weight_decay=0.01)
2022-06-30 03:48:27,057 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:48:35,709 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 03:48:38,125 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2022-06-30 03:49:01,627 - INFO - train_utils.py - load_model_and_parallel - 87 - Load ckpt from ./checkpoints/bert/model.pt
2022-06-30 03:49:02,644 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['0']
2023-11-26 10:00:36,270 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='./model_hub/bert-base-chinese/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=12, eval_steps=32, gpu_ids='-1', log_dir='./logs/', lr=1e-05, max_grad_norm=1, max_seq_len=256, num_tags=49, other_lr=0.0003, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=15, use_dev_num=32, use_tensorboard='True', warmup_proportion=0.1, weight_decay=0.01)
2023-11-26 10:01:42,656 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='./model_hub/bert-base-chinese/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=12, eval_steps=32, gpu_ids='-1', log_dir='./logs/', lr=1e-05, max_grad_norm=1, max_seq_len=256, num_tags=49, other_lr=0.0003, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=15, use_dev_num=32, use_tensorboard='True', warmup_proportion=0.1, weight_decay=0.01)
2023-11-26 10:02:34,500 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='./model_hub/bert-base-chinese/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=12, eval_steps=32, gpu_ids='-1', log_dir='./logs/', lr=1e-05, max_grad_norm=1, max_seq_len=256, num_tags=49, other_lr=0.0003, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=15, use_dev_num=32, use_tensorboard='True', warmup_proportion=0.1, weight_decay=0.01)
2023-11-26 10:02:36,025 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['-1']
2023-11-26 10:04:03,657 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='./model_hub/bert-base-chinese/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=12, eval_steps=32, gpu_ids='-1', log_dir='./logs/', lr=1e-05, max_grad_norm=1, max_seq_len=256, num_tags=49, other_lr=0.0003, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=15, use_dev_num=32, use_tensorboard='True', warmup_proportion=0.1, weight_decay=0.01)
2023-11-26 10:04:05,111 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['-1']
2023-11-26 10:05:04,165 - INFO - main.py - train - 63 - 【train】 epoch:0 0/81090 loss:273.9406 entity_loss:16.8917 head_loss:402.0263 tail_loss:402.9039
2023-11-26 10:05:58,603 - INFO - main.py - train - 63 - 【train】 epoch:0 1/81090 loss:256.4917 entity_loss:15.7166 head_loss:376.3349 tail_loss:377.4236
2023-11-26 10:20:57,587 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='./model_hub/bert-base-chinese/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=12, eval_steps=32, gpu_ids='-1', log_dir='./logs/', lr=1e-05, max_grad_norm=1, max_seq_len=256, num_tags=49, other_lr=0.0003, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=15, use_dev_num=32, use_tensorboard='True', warmup_proportion=0.1, weight_decay=0.01)
2023-11-26 10:20:59,124 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['-1']
2023-11-26 10:43:53,700 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='./model_hub/bert-base-chinese/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=12, eval_steps=32, gpu_ids='-1', log_dir='./logs/', lr=1e-05, max_grad_norm=1, max_seq_len=256, num_tags=49, other_lr=0.0003, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=15, use_dev_num=32, use_tensorboard='True', warmup_proportion=0.1, weight_decay=0.01)
2023-11-26 10:44:25,551 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='./model_hub/bert-base-chinese/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=12, eval_steps=32, gpu_ids='-1', log_dir='./logs/', lr=1e-05, max_grad_norm=1, max_seq_len=256, num_tags=49, other_lr=0.0003, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=15, use_dev_num=32, use_tensorboard='True', warmup_proportion=0.1, weight_decay=0.01)
2023-11-26 10:44:26,963 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['-1']
2023-11-26 11:01:01,325 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='./model_hub/bert-base-chinese/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=12, eval_steps=32, gpu_ids='-1', log_dir='./logs/', lr=1e-05, max_grad_norm=1, max_seq_len=256, num_tags=49, other_lr=0.0003, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=15, use_dev_num=32, use_tensorboard='True', warmup_proportion=0.1, weight_decay=0.01)
2023-11-26 11:01:03,013 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['-1']
2023-11-26 11:04:20,690 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='./model_hub/bert-base-chinese/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=12, eval_steps=32, gpu_ids='-1', log_dir='./logs/', lr=1e-05, max_grad_norm=1, max_seq_len=256, num_tags=49, other_lr=0.0003, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=15, use_dev_num=32, use_tensorboard='True', warmup_proportion=0.1, weight_decay=0.01)
2023-11-26 11:04:22,138 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['-1']
2023-11-26 11:05:44,728 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='./model_hub/bert-base-chinese/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=12, eval_steps=32, gpu_ids='-1', log_dir='./logs/', lr=1e-05, max_grad_norm=1, max_seq_len=256, num_tags=49, other_lr=0.0003, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=15, use_dev_num=32, use_tensorboard='True', warmup_proportion=0.1, weight_decay=0.01)
2023-11-26 11:05:46,258 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['-1']
2023-11-26 11:08:19,874 - INFO - main.py - <module> - 315 - Namespace(adam_epsilon=1e-08, bert_dir='./model_hub/bert-base-chinese/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=12, eval_steps=32, gpu_ids='-1', log_dir='./logs/', lr=1e-05, max_grad_norm=1, max_seq_len=256, num_tags=49, other_lr=0.0003, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=15, use_dev_num=32, use_tensorboard='True', warmup_proportion=0.1, weight_decay=0.01)
2023-11-26 11:08:21,347 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['-1']
2023-11-26 11:09:13,283 - INFO - main.py - train - 63 - 【train】 epoch:0 0/81090 loss:267.5727 entity_loss:16.2745 head_loss:392.8519 tail_loss:393.5915
2023-11-26 11:09:59,996 - INFO - main.py - train - 63 - 【train】 epoch:0 1/81090 loss:257.9206 entity_loss:15.7621 head_loss:378.6856 tail_loss:379.3141
2023-11-26 18:03:08,235 - INFO - main.py - <module> - 318 - Namespace(adam_epsilon=1e-08, bert_dir='./model_hub/bert-base-chinese/', data_dir='./data/ske', dropout_prob=0.1, eval_batch_size=12, eval_steps=32, gpu_ids='-1', log_dir='./logs/', lr=1e-05, max_grad_norm=1, max_seq_len=256, num_tags=49, other_lr=0.0003, output_dir='./checkpoints/', seed=123, train_batch_size=32, train_epochs=15, use_dev_num=32, use_tensorboard='True', warmup_proportion=0.1, weight_decay=0.01)
2023-11-26 18:03:09,892 - INFO - train_utils.py - load_model_and_parallel - 97 - Use single gpu in: ['-1']
2023-11-26 18:03:56,452 - INFO - main.py - train - 66 - 【train】 epoch:0 0/81090 loss:267.5812 entity_loss:16.3247 head_loss:392.8173 tail_loss:393.6017 speed: 40.97ms/b
2023-11-26 18:04:51,160 - INFO - main.py - train - 66 - 【train】 epoch:0 1/81090 loss:257.9290 entity_loss:15.8098 head_loss:378.6671 tail_loss:379.3101 speed: 54.71ms/b
2023-11-26 18:05:40,183 - INFO - main.py - train - 66 - 【train】 epoch:0 2/81090 loss:262.2436 entity_loss:16.0826 head_loss:385.0663 tail_loss:385.5818 speed: 49.02ms/b
2023-11-26 18:06:35,500 - INFO - main.py - train - 66 - 【train】 epoch:0 3/81090 loss:277.4138 entity_loss:17.0789 head_loss:407.2249 tail_loss:407.9376 speed: 55.32ms/b
2023-11-26 18:07:26,312 - INFO - main.py - train - 66 - 【train】 epoch:0 4/81090 loss:263.6770 entity_loss:16.2485 head_loss:387.0107 tail_loss:387.7718 speed: 50.81ms/b
2023-11-26 18:08:15,465 - INFO - main.py - train - 66 - 【train】 epoch:0 5/81090 loss:257.9492 entity_loss:15.7490 head_loss:378.6652 tail_loss:379.4334 speed: 49.15ms/b
2023-11-26 18:09:03,086 - INFO - main.py - train - 66 - 【train】 epoch:0 6/81090 loss:259.4170 entity_loss:15.8604 head_loss:380.8493 tail_loss:381.5413 speed: 47.62ms/b
2023-11-26 18:09:59,212 - INFO - main.py - train - 66 - 【train】 epoch:0 7/81090 loss:262.2396 entity_loss:16.0964 head_loss:384.9443 tail_loss:385.6782 speed: 56.12ms/b
2023-11-26 18:10:40,357 - INFO - main.py - train - 66 - 【train】 epoch:0 8/81090 loss:261.8321 entity_loss:16.0791 head_loss:384.4066 tail_loss:385.0107 speed: 41.14ms/b
2023-11-26 18:11:26,673 - INFO - main.py - train - 66 - 【train】 epoch:0 9/81090 loss:273.0386 entity_loss:16.7172 head_loss:400.8744 tail_loss:401.5243 speed: 46.31ms/b
2023-11-26 18:12:15,845 - INFO - main.py - train - 66 - 【train】 epoch:0 10/81090 loss:268.2588 entity_loss:16.4244 head_loss:393.8817 tail_loss:394.4701 speed: 49.17ms/b
2023-11-26 18:12:59,248 - INFO - main.py - train - 66 - 【train】 epoch:0 11/81090 loss:259.1377 entity_loss:15.9210 head_loss:380.5299 tail_loss:380.9623 speed: 43.40ms/b
2023-11-26 18:13:40,705 - INFO - main.py - train - 66 - 【train】 epoch:0 12/81090 loss:257.4521 entity_loss:15.7456 head_loss:377.9430 tail_loss:378.6678 speed: 41.46ms/b
2023-11-26 18:14:23,471 - INFO - main.py - train - 66 - 【train】 epoch:0 13/81090 loss:265.3517 entity_loss:16.2313 head_loss:389.5466 tail_loss:390.2771 speed: 42.77ms/b
2023-11-26 18:15:05,729 - INFO - main.py - train - 66 - 【train】 epoch:0 14/81090 loss:272.5602 entity_loss:16.7651 head_loss:400.1858 tail_loss:400.7296 speed: 42.26ms/b
2023-11-26 18:15:50,391 - INFO - main.py - train - 66 - 【train】 epoch:0 15/81090 loss:261.7051 entity_loss:16.1042 head_loss:384.2576 tail_loss:384.7535 speed: 44.66ms/b
2023-11-26 18:16:30,720 - INFO - main.py - train - 66 - 【train】 epoch:0 16/81090 loss:254.9846 entity_loss:15.7645 head_loss:374.2679 tail_loss:374.9215 speed: 40.33ms/b
2023-11-26 18:17:12,331 - INFO - main.py - train - 66 - 【train】 epoch:0 17/81090 loss:261.9739 entity_loss:16.0580 head_loss:384.5567 tail_loss:385.3069 speed: 41.61ms/b
